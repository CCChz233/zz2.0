# 系统完整性测试用例

## 测试环境准备

### 1. 确保服务运行
```bash
# 终端1: GPT-Researcher (端口 8000)
cd /Users/chz/code/zz3.0/gpt-researcher
python -m uvicorn main:app --reload --port 8000

# 终端2: 后端 Flask (端口 5001)
cd /Users/chz/code/zz3.0/backend
python app.py

# 终端3: 前端 (如果使用开发模式)
cd /Users/chz/code/zz3.0/vue-admin-zhizhen
npm run serve
```

---

## 测试用例分类

### 一、GPT-Researcher 研究任务测试

#### 用例 1.1: 基础研究任务
**输入**: `研究一下人工智能的最新发展`

**预期结果**:
- ✅ 自动路由到 GPT-Researcher
- ✅ 返回详细的结构化研究报告
- ✅ 包含多个章节（算法、应用、伦理等）
- ✅ 流式响应正常显示
- ✅ 对话历史保存成功

**验证点**:
- [ ] 响应时间较长（研究任务需要时间）
- [ ] 内容详细（>1000字符）
- [ ] 格式规范（Markdown）
- [ ] 包含章节标题（###）

---

#### 用例 1.2: 行业研究
**输入**: `分析一下高端科学仪器行业的市场趋势`

**预期结果**:
- ✅ 使用 GPT-Researcher
- ✅ 返回行业分析报告
- ✅ 包含市场数据和分析

---

#### 用例 1.3: 政策研究
**输入**: `研究一下近期的高端科学仪器国产化相关政策`

**预期结果**:
- ✅ 使用 GPT-Researcher
- ✅ 返回政策研究报告
- ✅ 包含政策要点和时间线

---

#### 用例 1.4: 技术调研
**输入**: `调研一下原子力显微镜的技术突破`

**预期结果**:
- ✅ 使用 GPT-Researcher
- ✅ 返回技术调研报告
- ✅ 包含技术细节和应用场景

---

### 二、Qwen 通用聊天测试

#### 用例 2.1: 简单问候
**输入**: `你好`

**预期结果**:
- ✅ 使用 Qwen（默认服务）
- ✅ 返回简短友好的回复
- ✅ 响应速度快（<5秒）
- ✅ 流式响应正常

**验证点**:
- [ ] 响应时间短
- [ ] 内容简洁（<500字符）
- [ ] 语气友好

---

#### 用例 2.2: 知识问答
**输入**: `什么是量子计算？`

**预期结果**:
- ✅ 使用 Qwen
- ✅ 返回知识性回答
- ✅ 解释清晰易懂

---

#### 用例 2.3: 日常对话
**输入**: `今天天气怎么样？`

**预期结果**:
- ✅ 使用 Qwen
- ✅ 返回对话式回复
- ✅ 可能提示无法获取实时天气

---

#### 用例 2.4: 业务咨询
**输入**: `致真精密仪器公司的主要产品是什么？`

**预期结果**:
- ✅ 使用 Qwen
- ✅ 基于系统提示词中的公司信息回答
- ✅ 内容准确

---

### 三、流式响应测试

#### 用例 3.1: 研究任务流式响应
**输入**: `研究一下区块链技术`

**预期结果**:
- ✅ 流式显示内容（逐字或逐句）
- ✅ 实时更新界面
- ✅ 自动滚动到底部
- ✅ 完成后停止

**验证点**:
- [ ] 内容逐步显示
- [ ] 界面不卡顿
- [ ] 滚动正常

---

#### 用例 3.2: 通用聊天流式响应
**输入**: `介绍一下Python编程语言`

**预期结果**:
- ✅ 流式显示
- ✅ 响应速度快
- ✅ 实时更新

---

### 四、对话历史测试

#### 用例 4.1: 多轮对话
**步骤**:
1. 输入: `你好`
2. 输入: `介绍一下你自己`
3. 输入: `你能做什么？`

**预期结果**:
- ✅ 每轮对话都保存
- ✅ 上下文连贯
- ✅ AI 能理解之前的对话

---

#### 用例 4.2: 对话上下文
**步骤**:
1. 输入: `我想了解量子计算`
2. 输入: `它有什么应用？`（指代量子计算）

**预期结果**:
- ✅ AI 理解"它"指量子计算
- ✅ 回答相关应用场景

---

#### 用例 4.3: 会话持久化
**步骤**:
1. 发送消息，获取 session_id
2. 刷新页面或重新打开
3. 使用相同 session_id 继续对话

**预期结果**:
- ✅ 能加载历史对话
- ✅ 可以继续之前的对话

---

### 五、任务路由测试

#### 用例 5.1: 边界情况 - 模糊任务
**输入**: `帮我分析一下数据`

**预期结果**:
- ⚠️ 可能路由到 GPT-Researcher（包含"分析"）
- 或路由到 Qwen（如果"数据"关键词权重更高）

**建议**: 根据实际业务需求调整关键词权重

---

#### 用例 5.2: 混合任务
**输入**: `研究一下数据分析的最新方法`

**预期结果**:
- ✅ 路由到 GPT-Researcher（"研究"关键词优先）
- ✅ 返回研究报告

---

#### 用例 5.3: 明确指定任务类型
**输入**: `报告：高端科学仪器市场分析`

**预期结果**:
- ✅ 路由到 GPT-Researcher
- ✅ 返回市场分析报告

---

### 六、错误处理测试

#### 用例 6.1: 空消息
**输入**: ``（空字符串）

**预期结果**:
- ✅ 前端阻止发送
- ✅ 显示提示信息

---

#### 用例 6.2: 超长消息
**输入**: `（输入超过 10000 字符的消息）`

**预期结果**:
- ✅ 前端限制输入长度
- ✅ 或后端返回错误提示

---

#### 用例 6.3: 服务不可用
**场景**: 停止 GPT-Researcher 服务

**输入**: `研究一下人工智能`

**预期结果**:
- ✅ 后端自动回退到 Qwen
- ✅ 返回错误提示或使用备用服务
- ✅ 前端显示友好错误信息

---

#### 用例 6.4: 网络超时
**场景**: 模拟网络延迟

**输入**: `研究一下复杂主题`

**预期结果**:
- ✅ 显示超时错误
- ✅ 提供重试选项

---

### 七、Markdown 渲染测试

#### 用例 7.1: 研究任务 Markdown
**输入**: `研究一下人工智能`

**预期结果**:
- ✅ 标题正确渲染（###）
- ✅ 列表正确显示（- 或 *）
- ✅ 代码块正确显示（如果有）
- ✅ 链接正确显示（如果有）

---

#### 用例 7.2: 复杂格式
**输入**: `研究一下Python编程，包括语法和最佳实践`

**预期结果**:
- ✅ 所有 Markdown 元素正确渲染
- ✅ 样式美观
- ✅ 可读性好

---

### 八、性能测试

#### 用例 8.1: 响应时间
**测试**: 测量不同类型任务的响应时间

**预期结果**:
- 通用聊天（Qwen）: < 5秒
- 研究任务（GPT-Researcher）: 30-120秒（正常）

---

#### 用例 8.2: 并发测试
**场景**: 同时发送多个请求

**预期结果**:
- ✅ 系统能处理并发请求
- ✅ 不会崩溃
- ✅ 响应时间合理

---

### 九、系统提示词测试

#### 用例 9.1: 基础提示词
**验证**: AI 回复是否符合系统提示词中的角色设定

**预期结果**:
- ✅ 语气友好、专业
- ✅ 符合"致真智能体"的角色

---

#### 用例 9.2: 业务上下文
**输入**: `致真精密仪器公司的主要业务是什么？`

**预期结果**:
- ✅ 基于配置文件中的业务信息回答
- ✅ 内容准确

---

### 十、集成测试场景

#### 场景 10.1: 完整工作流
**步骤**:
1. 打开前端界面
2. 发送研究任务: `研究一下量子计算`
3. 等待完整响应
4. 发送后续问题: `它在哪些领域有应用？`
5. 发送通用问题: `你好`
6. 检查对话历史

**预期结果**:
- ✅ 所有步骤正常
- ✅ 任务路由正确
- ✅ 对话连贯
- ✅ 历史保存

---

#### 场景 10.2: 多任务切换
**步骤**:
1. 研究任务: `研究一下区块链`
2. 通用聊天: `你好`
3. 研究任务: `分析一下市场趋势`
4. 通用聊天: `谢谢`

**预期结果**:
- ✅ 每次都能正确路由
- ✅ 上下文不混乱
- ✅ 响应正常

---

## 测试检查清单

### 功能检查
- [ ] GPT-Researcher 研究任务正常工作
- [ ] Qwen 通用聊天正常工作
- [ ] 任务路由准确
- [ ] 流式响应正常
- [ ] 对话历史保存
- [ ] Markdown 渲染正确
- [ ] 错误处理完善

### 性能检查
- [ ] 响应时间合理
- [ ] 流式响应流畅
- [ ] 界面不卡顿
- [ ] 内存使用正常

### 用户体验检查
- [ ] 界面友好
- [ ] 提示信息清晰
- [ ] 错误信息友好
- [ ] 加载状态明显

---

## 推荐测试顺序

1. **基础功能测试**（用例 2.1, 1.1）
   - 先测试通用聊天，确保基础功能正常
   - 再测试研究任务，验证路由功能

2. **流式响应测试**（用例 3.1, 3.2）
   - 验证流式显示是否正常

3. **对话历史测试**（用例 4.1, 4.2）
   - 验证多轮对话和上下文理解

4. **边界情况测试**（用例 6.1-6.4）
   - 验证错误处理

5. **集成测试**（场景 10.1, 10.2）
   - 完整工作流测试

---

## 快速测试脚本

```bash
# 测试1: 通用聊天（Qwen）
curl -X POST http://localhost:5001/api/agent/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "你好", "session_id": "test-chat"}'

# 测试2: 研究任务（GPT-Researcher）
curl -X POST http://localhost:5001/api/agent/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "研究一下人工智能", "session_id": "test-research"}'

# 测试3: 流式响应
curl -X POST http://localhost:5001/api/agent/chat/stream \
  -H "Content-Type: application/json" \
  -d '{"message": "介绍一下Python", "session_id": "test-stream"}'
```

